[{"path":"https://jean997.github.io/GFA/articles/gfa_with_gwas_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Running GFA with GWAS Data","text":"vignette, walk ","code":""},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Running GFA with Simulated Data","text":"vignette simulate two toy data sets analyze GFA. first toy data set simple example shown Figure 1 paper. second toy data set complex. includes traits, complicated factor structure, data simulated LD. second data set, compare results without accounting correlation due overlapping samples.","code":""},{"path":[]},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"simulate-simple-data","dir":"Articles","previous_headings":"Simple Example","what":"Simulate simple data","title":"Running GFA with Simulated Data","text":"start constructing plotting true factor structure. GFA includes convenience function plot_factors plotting matrices heatmaps.  Next simulate data using sim_lf function GWASBrewer simulates GFA model, \\[ \\hat{B} = LF^\\top + \\Theta + E \\] \\(F\\) factor structure, \\(L\\) randomly generated matrix variant-factor effects, \\(\\Theta\\) additional matrix direct trait effects, \\(E\\) measurement error. first example toy example designed strong signal can seen visually, don’t consider parameters realistic. use three traits heritability 0.5, GWAS sample size \\(50,000\\), 80% trait heritability explained two factors. generate 10k independent SNPs (LD). \\(L\\) \\(\\Theta\\) 10% non-zero elements. overlap GWAS samples. illustrative purposes, plot simulated effect estimates \\(\\beta_hat\\), selecting SNPS acting range possible pathways large effect sizes pattern clear visually.","code":"set.seed(100) # True factor structure myF <- matrix(c(0, -1, 1, 1, 2, 1), nrow = 3, byrow = TRUE)  myF <- apply(myF, 2, function(x){x/sqrt(sum(x^2))})  p <- plot_factors(myF, row_names = c(\"T3\", \"T2\", \"T1\"), col_names = c(\"F1\", \"F2\")) +      scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2], name = \"Normalized\\nEffect\") +      xlab(\"Mediator\") +      ggtitle(\"True Mediator Network\") +      scale_x_discrete(position = \"top\")+      theme(axis.text.x = element_text(angle = 0),            panel.background = element_rect(fill = \"white\"),            axis.ticks = element_blank()) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. p dat <- GWASBrewer::sim_lf(F_mat = myF,                            N = 50000,                            J = 10000,                            h2_trait = rep(0.5, 3),                           omega = rep(0.8, 3),                            pi_L = rep(0.1,2),                            pi_theta = 0.1,                            est_s = TRUE) #> SNP effects provided for 10000 SNPs and 3 traits. # Null SNPS which do not effect factors or have additional effects in theta ix0 <- sample(which((rowSums(dat$L_mat_joint == 0) == 2) & (rowSums(dat$theta_joint == 0) == 3)), size = 8) # SNPS which only effect trait 1 directly and not through factors ix1 <- sample(which((rowSums(dat$L_mat_joint == 0) == 2) & (rowSums(dat$theta_joint == 0) == 2) & abs(dat$theta_joint[,1])> 0.02), size = 4) # SNPS which only effect trait 2 directly and not through factors ix2 <- sample(which((rowSums(dat$L_mat_joint == 0) == 2) & (rowSums(dat$theta_joint == 0) == 2) & abs(dat$theta_joint[,2])> 0.02), size = 5) # SNPS which only effect trait 3 directly and not through factors ix3 <- sample(which((rowSums(dat$L_mat_joint == 0) == 2) & (rowSums(dat$theta_joint == 0) == 2) & abs(dat$theta_joint[,3])> 0.02), size = 3) # SNPS which only effect effect factor 1  ix4 <- sample(which((rowSums(dat$L_mat_joint == 0) == 1) & abs(dat$L_mat_joint[,1]) > 0.07 & (rowSums(dat$theta_joint == 0) == 3)), size = 6) # SNPS which only effect factor 2  ix5 <- sample(which((rowSums(dat$L_mat_joint == 0) == 1) & abs(dat$L_mat_joint[,2]) > 0.07 & (rowSums(dat$theta_joint == 0) == 3)), size = 4)  X <- dat$beta_hat[c(ix0, ix1, ix2, ix3, ix4, ix5),][,c(3,2,1)] se <- dat$s_estimate[c(ix0, ix1, ix2, ix3, ix4, ix5),][, c(3,2,1)] plot_factors(X, col_names = c(\"T1\", \"T2\", \"T3\")) +   scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2], name = \"Beta hat\") +   xlab(\"Trait\") +   ylab(\"Variant\") +   ggtitle(\"Variant-Trait Associations\") +   scale_x_discrete(position = \"top\")+   theme(axis.text.x = element_text(angle = 0),            panel.background = element_rect(fill = \"white\"),            axis.ticks = element_blank()) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale."},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"fit-gfa-to-simple-data","dir":"Articles","previous_headings":"Simple Example","what":"Fit GFA to simple data","title":"Running GFA with Simulated Data","text":"typical GFA analysis real data, next step estimate nuisance correlation matrix. toy example, sample overlap, skip step, include next example. fit GFA toy data, use gfa_fit function. gfa_fit can take two types input, either z-scores sample size effect estimates standard errors. know sample size GWAS, better use z-scores sample size. either case, GFA fit using z-scores fitted factors re-scaled standardized trait scale. z-scores provided sample size given, factors can still estimated, left z-score scale depends sample size may interpretable. discuss scaling greater detail later vignette. resulting fit object contains following elements: F_hat: estimated factor structure standardized trait scale L_hat: Estimated variant-factor effects F_hat_single: Subset columns F_hat corresponding single-trait factors. F_hat_multi: Columns F_hat corresponding multi-trait factors. F_hat_est: estimated factors estimated (z-score) scale (usually needed). gfa_pve: object containing genet_var pve. genet_var trait heritability explained fitted model. pve proportion heritability trait (rows) explained factor (columns). scale, method, params fit internal use. can plot estimated factors using plot_factors function:  factors capture truth quite well. Note estimated factors different order original. important keep mind ordering factors arbitrary. sign column also arbitrary. also third factor effects (almost) trait 2. captures direct effects trait 2 mediated factors. convenience, GFA try identify single trait factors separate , dividing F_hat F_single F_multi described . GFA restricted produce number factors equal number traits. occurs example coincidence. comparison can try svd applied z-scores significant variants decomposes \\(\\hat{Z}\\) \\(UDV^\\top\\) . equivalent estimate factors estimate \\(V\\). Note always best run GFA variants LD-pruned subset significant.  first SVD factor good estimate true factor F2 subsequent columns correspond true factors constrained orthogonal first.","code":"Z_hat = with(dat, beta_hat/s_estimate) fit_toy <- gfa_fit(Z_hat = Z_hat,                     N = rep(50000, 3)) #> R is not supplied, fitting assuming full independence #> Adding factor 1 to flash object... #> Adding factor 2 to flash object... #> Adding factor 3 to flash object... #> Adding factor 4 to flash object... #> Factor doesn't significantly increase objective and won't be added. #> Wrapping up... #> Done. #> Backfitting 3 factors (tolerance: 4.47e-04)... #>   Difference between iterations is within 1.0e+02... #>   Difference between iterations is within 1.0e+01... #>   Difference between iterations is within 1.0e+00... #>   Difference between iterations is within 1.0e-01... #>   Difference between iterations is within 1.0e-02... #>   Difference between iterations is within 1.0e-03... #> Wrapping up... #> Done. #> Nullchecking 3 factors... #> Done. #> begin while #> Nullchecking 3 factors... #> Done. names(fit_toy) #>  [1] \"fit\"          \"method\"       \"L_hat\"        \"F_hat\"        \"F_hat_single\" #>  [6] \"F_hat_multi\"  \"scale\"        \"gfa_pve\"      \"mode\"         \"params\" fit_toy$F_hat %>%     plot_factors(., col_names = c(\"EF1\", \"EF2\", \"EF3\")) +   scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2], name = \"Normalized\\nEffect\") +   xlab(\"Mediator\") +   ylab(\"Trait\") +   ggtitle(\"Estimated Mediator Network (GFA)\") +   scale_x_discrete(position = \"top\")+   theme(axis.text.x = element_text(angle = 0),            panel.background = element_rect(fill = \"white\"),            axis.ticks = element_blank()) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. maxz <- apply(abs(Z_hat), 1, max) Z_hat_top <- Z_hat[maxz > 5.45,] ## corresponds to p < 5e-8  fit_svd <- svd(Z_hat_top)  fit_svd$v %>%   plot_factors(., col_names = c(\"EF1\", \"EF2\", \"EF3\")) +   scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2], name = \"Normalized\\nEffect\") +   xlab(\"Mediator\") +   ylab(\"Trait\") +   ggtitle(\"Estimated Mediator Network (SVD)\") +   scale_x_discrete(position = \"top\")+   theme(axis.text.x = element_text(angle = 0),            panel.background = element_rect(fill = \"white\"),            axis.ticks = element_blank()) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale."},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"more-complex-example","dir":"Articles","previous_headings":"","what":"More Complex Example","title":"Running GFA with Simulated Data","text":"Next generate analyze complicated data including LD sample overlap. use LD pattern built GWASBrewer package estimated chromosome 19 European subset 1k Genomes. First set simulation parameters. 20 traits, 100k variants, 5 unobserved factors. GWAS sample size 20 traits range 30k 50k 30k samples common GWAS traits. proportion non-zero effects set , average, 1k SNPs affecting factor 1k SNPs affecting trait directly. Next generate factor structure. use generate_random_F function GWASBrewer. function requires sampling function drawing factor-trait effects, number traits affected factor, total trait heritability, proportion heritability trait explained factors, heritability factors. example, generate factor structures find one every trait affected least one factor. Since GWAS samples overlap, environmental correlation traits affect final GWAS estimates. Since factors environmental component, trait environmental correlation mediated factors. can specify correlation environmental components traits mediated factors. example, use block correlation structure. Now ready generate data. can take look generated true factor structure.  simulated data also contains objects describing trait covariance. traits scaled total variance 1. dat$Sigma_G gives genetic variance-covariance matrix, diagonal matrix gives heritability. dat$Sigma_E gives environmental variance-covariance matrix, total trait correlation dat$Sigma_E + dat$Sigma_G. Useful purposes, dat$R gives residual correlation effect estimates equal dat$trait_cor elements scaled proportion overlap GWAS.","code":"data(\"AF\") data(\"ld_mat_list\") length(ld_mat_list) #> [1] 39 set.seed(201) ntrait <- 20 nvar <- 100000 nfactor <- 5  # specify sample size matrix Nmat <- matrix(30000, nrow = ntrait, ncol = ntrait) Nunique <- ceiling(runif(n = 20, min = 0, max = 20000)) diag(Nmat) <- diag(Nmat) + Nunique  # proportion of effect variants pi_L <- pi_theta <- 1000/nvar # sampling function g_F <- function(n){runif(n, -1, 1)} # number of traits affected by each factor nz_factor <- pmin(rpois(nfactor, 5)+1, ntrait) # heritability of each trait h2_trait <- runif(n=ntrait, 0.05, 0.3) # proportion of trait variance explained by factors omega <- runif(n=ntrait, 0.5, 1) # heritability of each factor h2_factor <- runif(n=nfactor, 0.5, 1) done <- FALSE while(!done){   #cat(\"going..\")   myF <- generate_random_F(K = nfactor, M = ntrait, g_F = g_F,                           nz_factor = nz_factor, omega = omega,                           h2_trait = h2_trait)   x <- rowSums(myF^2)   if(all(x > 0)) done <- TRUE } Rblock <- matrix(0.5, 4, 4) diag(Rblock) <- 1 R_E <- kronecker(diag(5), Rblock) dat2 <-  sim_lf(F_mat = myF, N=Nmat, J=nvar, h2_trait = h2_trait,             omega = omega, h2_factor = h2_factor,             pi_L = rep(pi_L, nfactor), pi_theta = pi_theta,             R_E = R_E,              R_LD = ld_mat_list, af = AF,              est_s = TRUE)  #> SNP effects provided for 100000 SNPs and 20 traits. dat2 <- GWASBrewer:::calc_ld_scores(dat2, ld_mat_list) p <- dat2$F_mat %>%     GFA:::norm_cols() %>%     with(., A) %>%   plot_factors(.) +   scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2], name = \"Normalized\\nEffect\") +   xlab(\"Mediator\") +   ylab(\"Trait\") +   #ggtitle(\"Mediator Network\") +   #scale_x_discrete(position = \"top\")+   theme(axis.text.x = element_text(angle = 0),            panel.background = element_rect(fill = \"white\"),            axis.ticks = element_blank(),      axis.text = element_text(size = 12),     title = element_text(size = 20),         legend.position = \"none\") #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. p"},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"estimate-nuisance-correlation","dir":"Articles","previous_headings":"More Complex Example","what":"Estimate Nuisance Correlation","title":"Running GFA with Simulated Data","text":"Since sample overlap, estimate residual correlation. can using either R_ldsc R_pt use LD-score regression p-value thresholding methods. LD-score regression method, need provide LD scores computed GWASBrewer. can take look estimated \\(R\\) vs true \\(R\\). LD-score method gives accurate estimate takes longer compute.      LDSC estimate closer truth, GFA sensitive difference.","code":"Z_hat <- with(dat2, beta_hat/s_estimate) ldscores <- dat2$snp_info$l2 R1 <- R_ldsc(Z_hat, ldscores = ldscores, ld_size = nrow(Z_hat), N = diag(Nmat))  R2 <- with(dat2, R_pt(beta_hat, s_estimate, p_val_thresh = 0.05)) plot_factors(dat2$R) + theme(axis.title =  element_blank()) + ggtitle(\"True R\") plot_factors(R1$Se) + theme(axis.title =  element_blank()) + ggtitle(\"Estimated R - LDSC\") plot_factors(R2) + theme(axis.title =  element_blank()) + ggtitle(\"Estimated R - p threshold\") plot(dat2$R, R2, xlab = \"True Correlation\", ylab = \"Estimated Correlation - p threshold\") abline(0, 1) plot(dat2$R, R1$Se, xlab = \"True Correlation\", ylab = \"Estimated Correlation - LDSC\") abline(0, 1)"},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"fit-gfa","dir":"Articles","previous_headings":"More Complex Example","what":"Fit GFA","title":"Running GFA with Simulated Data","text":"fit GFA, need obtain independent (LD-pruned) set variants. can use GWASBrewer find simulated data set. Note threshold p-value. ok prioritize variants minimum p-value LD pruning, just prune randomly. Finally, can fit GFA without adjustment sample overlap provided R argument. Recall R1 estimated using LD-score regression R2 estimated using p-value thresholding. can compare results fitting GFA using true nuisance correlation matrix, example, get nearly identical results using either estimate R truth. settings, able accurately recover five factors. can see using min_norm function compares two factor matrices finding rotation, \\(Q\\) minimized frobenious norm \\(\\vert \\vert F_1 - Q F_2 \\vert \\vert_{F}\\). min_norm function report factors match matrices, well match, well overall frobenious norm. frobenious norm 0 means matrices exactly . value frobenious norm can roughly interpreted number factors \\(F_2\\) match \\(F_1\\) plus number factors \\(F_1\\) match \\(F_2\\), partial scores partially matching factors. example, can first compare true factor structure first GFA estimate. shows five factors recovered high correlation. value val column solution element equal normalized inner product two factors, approximately equal correlation. Looking frobenious norm values, can see GFA estimates included nuisance correlation similar. compare results results omitted R argument, can see adjusting nuisance correlation resulted four extra factors estimated don’t match true factors. correlation matching factors also slightly lower result account sample overlap. two factors given scores NA single trait factors don’t count towards overall forbenious norm score. value opt_frob_n shows best score achievable selecting subset estimated factors. can see , even knew factors remove, still worse match achieved method accounts sample overlap. Plotting factors estimated without correction overlapping samples, shows factor structure extra factors mimics structure environmental correlation. can also see matching factors estimated fit0 contaminated structure environmental correlation. plot multi-trait factors.","code":"ix <- sim_ld_prune(dat2, R_LD = ld_mat_list, r2_thresh = 0.01) #> pvalue omitted so variants will be prioritized randomly Z_hat_indep <- Z_hat[ix,] dim(Z_hat_indep) #> [1] 4939   20 fit0 <- gfa_fit(Z_hat  = Z_hat_indep, N = diag(Nmat)) #> R is not supplied, fitting assuming full independence #> Adding factor 1 to flash object... #> Adding factor 2 to flash object... #> Adding factor 3 to flash object... #> Adding factor 4 to flash object... #> Adding factor 5 to flash object... #> Adding factor 6 to flash object... #> Adding factor 7 to flash object... #> Adding factor 8 to flash object... #> Adding factor 9 to flash object... #> Adding factor 10 to flash object... #> Adding factor 11 to flash object... #> Factor doesn't significantly increase objective and won't be added. #> Wrapping up... #> Done. #> Backfitting 10 factors (tolerance: 1.47e-03)... #>   Difference between iterations is within 1.0e+01... #>   Difference between iterations is within 1.0e+00... #>   Difference between iterations is within 1.0e-01... #>   Difference between iterations is within 1.0e-02... #>   Difference between iterations is within 1.0e-03... #> Wrapping up... #> Done. #> Nullchecking 10 factors... #> Done. #> begin while #> Nullchecking 10 factors... #> Done. fit1 <- gfa_fit(Z_hat = Z_hat_indep, N = diag(Nmat),  R = R1$Se) #> Warning in check_R(R, dat$p, params): R has values different from 1 on the #> diagonal. This is ok. #> Adding factor 1 to flash object... #> Adding factor 2 to flash object... #> Adding factor 3 to flash object... #> Adding factor 4 to flash object... #> Adding factor 5 to flash object... #> Adding factor 6 to flash object... #> Adding factor 7 to flash object... #> Adding factor 8 to flash object... #> Adding factor 9 to flash object... #> Adding factor 10 to flash object... #> Adding factor 11 to flash object... #> Adding factor 12 to flash object... #> Factor doesn't significantly increase objective and won't be added. #> Wrapping up... #> Done. #> Backfitting 28 factors (tolerance: 1.47e-03)... #>   --Estimate of factor 5 is numerically zero! #>   --Estimate of factor 6 is numerically zero! #>   --Estimate of factor 7 is numerically zero! #>   --Estimate of factor 8 is numerically zero! #>   --Estimate of factor 10 is numerically zero! #>   Difference between iterations is within 1.0e+04... #>   Difference between iterations is within 1.0e+03... #>   Difference between iterations is within 1.0e+02... #>   Difference between iterations is within 1.0e+01... #>   Difference between iterations is within 1.0e+00... #>   Difference between iterations is within 1.0e-01... #>   Difference between iterations is within 1.0e-02... #>   Difference between iterations is within 1.0e-03... #> Wrapping up... #> Done. #> Nullchecking 28 factors... #>   5 factors are identically zero. #> Factor22set to zero, increasing objective by 9.648e+00. #> Factor26set to zero, increasing objective by 1.057e+01. #> Factor27set to zero, increasing objective by 7.763e+00. #> Factor28set to zero, increasing objective by 1.118e+01. #> Wrapping up... #>   Removed 9 factors. #> Done. #> begin while #> Nullchecking 19 factors... #> Factor6set to zero, increasing objective by 1.623e+02. #> Factor18set to zero, increasing objective by 4.582e+00. #> Factor19set to zero, increasing objective by 6.542e+00. #> Wrapping up... #>   Removed 3 factors. #> Done. fit2 <- gfa_fit(Z_hat = Z_hat_indep, N = diag(Nmat),  R = R2) #> Adding factor 1 to flash object... #> Adding factor 2 to flash object... #> Adding factor 3 to flash object... #> Adding factor 4 to flash object... #> Adding factor 5 to flash object... #> Adding factor 6 to flash object... #> Adding factor 7 to flash object... #> Adding factor 8 to flash object... #> Adding factor 9 to flash object... #> Adding factor 10 to flash object... #> Adding factor 11 to flash object... #> Adding factor 12 to flash object... #> Factor doesn't significantly increase objective and won't be added. #> Wrapping up... #> Done. #> Backfitting 28 factors (tolerance: 1.47e-03)... #>   --Estimate of factor 8 is numerically zero! #>   --Estimate of factor 10 is numerically zero! #>   --Estimate of factor 5 is numerically zero! #>   --Estimate of factor 6 is numerically zero! #>   --Estimate of factor 7 is numerically zero! #>   Difference between iterations is within 1.0e+04... #>   Difference between iterations is within 1.0e+03... #>   Difference between iterations is within 1.0e+02... #>   Difference between iterations is within 1.0e+01... #>   Difference between iterations is within 1.0e+00... #>   Difference between iterations is within 1.0e-01... #>   Difference between iterations is within 1.0e-02... #>   Difference between iterations is within 1.0e-03... #> Wrapping up... #> Done. #> Nullchecking 28 factors... #>   5 factors are identically zero. #> Factor22set to zero, increasing objective by 3.888e+01. #> Factor23set to zero, increasing objective by 3.826e+01. #> Factor24set to zero, increasing objective by 3.264e+01. #> Factor25set to zero, increasing objective by 4.091e+01. #> Factor26set to zero, increasing objective by 2.425e+01. #> Factor27set to zero, increasing objective by 3.229e+01. #> Factor28set to zero, increasing objective by 2.313e+01. #> Wrapping up... #>   Removed 12 factors. #> Done. #> begin while #> Nullchecking 16 factors... #> Factor6set to zero, increasing objective by 1.067e+02. #> Wrapping up... #>   Removed one factor. #> Done. fitoracle <- gfa_fit(Z_hat  = Z_hat_indep, N = diag(Nmat), R = dat2$R) #> Adding factor 1 to flash object... #> Adding factor 2 to flash object... #> Adding factor 3 to flash object... #> Adding factor 4 to flash object... #> Adding factor 5 to flash object... #> Adding factor 6 to flash object... #> Adding factor 7 to flash object... #> Adding factor 8 to flash object... #> Adding factor 9 to flash object... #> Adding factor 10 to flash object... #> Adding factor 11 to flash object... #> Adding factor 12 to flash object... #> Factor doesn't significantly increase objective and won't be added. #> Wrapping up... #> Done. #> Backfitting 28 factors (tolerance: 1.47e-03)... #>   --Estimate of factor 5 is numerically zero! #>   --Estimate of factor 6 is numerically zero! #>   --Estimate of factor 7 is numerically zero! #>   --Estimate of factor 8 is numerically zero! #>   --Estimate of factor 10 is numerically zero! #>   Difference between iterations is within 1.0e+04... #>   Difference between iterations is within 1.0e+03... #>   Difference between iterations is within 1.0e+02... #>   Difference between iterations is within 1.0e+01... #>   Difference between iterations is within 1.0e+00... #>   Difference between iterations is within 1.0e-01... #>   Difference between iterations is within 1.0e-02... #> Wrapping up... #> Done. #> Nullchecking 28 factors... #>   5 factors are identically zero. #> Factor24set to zero, increasing objective by 6.277e+00. #> Factor26set to zero, increasing objective by 1.314e+01. #> Factor27set to zero, increasing objective by 9.652e+00. #> Factor28set to zero, increasing objective by 2.052e+01. #> Wrapping up... #>   Removed 9 factors. #> Done. #> begin while #> Nullchecking 19 factors... #> Factor6set to zero, increasing objective by 1.578e+02. #> Factor17set to zero, increasing objective by 6.327e+00. #> Factor18set to zero, increasing objective by 3.836e+00. #> Factor19set to zero, increasing objective by 1.115e+01. #> Wrapping up... #>   Removed 4 factors. #> Done. min_norm(f_true = dat2$F_mat, f_hat = fit1$F_hat) #> $solution #>   true_ix est_ix max_true_val max_hat_val     penalty match_score #> 1       5      4    0.5387060   0.5291128 0.001436740   0.9992816 #> 2       1      2    0.5082579   0.4920455 0.003164712   0.9984176 #> 3       4      1    0.5321195   0.5697020 0.005522261   0.9972389 #> 4       3      3    0.5828887   0.5819004 0.013035870   0.9934821 #> 5       2      5    0.7047004   0.7606438 0.015395358   0.9923023 #>  #> $frob_n #> [1] 0.1963541 min_norm(f_true = dat2$F_mat, f_hat = fit1$F_hat)$frob_n #> [1] 0.1963541 min_norm(f_true = dat2$F_mat, f_hat = fit2$F_hat)$frob_n #> [1] 0.2314396 min_norm(f_true = dat2$F_mat, f_hat = fitoracle$F_hat)$frob_n #> [1] 0.1906022 min_norm(f_true = dat2$F_mat, f_hat = fit0$F_hat) #> There are  1  single trait factors in f_hat #> $solution #>    true_ix est_ix max_true_val max_hat_val     penalty match_score #> 1        4      1    0.5321195   0.5486638 0.002814011   0.9985930 #> 2        5      4    0.5387060   0.5310407 0.004892544   0.9975537 #> 3        3      3    0.5828887   0.5858742 0.014126643   0.9929367 #> 4        1      2    0.5082579   0.5023813 0.070248731   0.9648756 #> 5        2      7    0.7047004   0.7111798 0.097523443   0.9512383 #> 6       NA      9           NA   0.4175495 1.000000000   0.0000000 #> 7       NA      8           NA   0.4232410 1.000000000   0.0000000 #> 8       NA      5           NA   0.3864060 1.000000000   0.0000000 #> 9       NA      6           NA   0.5245608 1.000000000   0.0000000 #> 10      NA     10           NA   0.9999966          NA          NA #>  #> $frob_n #> [1] 2.046853 p0 <- fit0$F_hat_multi %>%    plot_factors(.) +   scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2]) +   xlab(\"Factor\") +   ylab(\"Trait\") +   ggtitle(\"Without Sample Overlap Correction\")  #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.  p1 <- fit1$F_hat_multi %>%    plot_factors(.) +   scale_fill_gradient2(low = viridis(3)[1], high = viridis(3)[2]) +   xlab(\"Factor\") +   ylab(\"Trait\") +   ggtitle(\"With Sample Overlap Correction\")  #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. p0 p1"},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"understanding-scaling-within-and-between-factors","dir":"Articles","previous_headings":"","what":"Understanding Scaling Within and Between Factors","title":"Running GFA with Simulated Data","text":"data supplied z-scores sample sizes, effects F_hat returned standardized effect scale. example, first column F_hat equal \\((1, 2, 0)\\), mean , unit increase first factor, 1 sd increase trait 1, 2 sd increase trait 2 change trait 3. However scale inferred factor arbitrary, factor \\((1, 2, 0)\\) equivalent factor \\((0.1, 0.2, 0)\\). means appropriate interpretation factor \\((1, 2, 0)\\) first factor effect trait 2 twice big effect trait 1 units trait standard deviations. plotting convenience, output, always scale factors columns F_hat norm 1. z-scores sample sizes provided, effects F_hat returned z-score scale, proportional trait standard deviation divided times square root sample size. Since sample size study design parameter, effects immediately interpretable, converted standardized trait scale dividing row F_hat square root sample size corresponding trait. effect estimates standard errors supplied, effects F_hat returned natural scale, .e. scale trait used GWAS. Alternatively, effects natural scale desired, GFA can fit using z-scores, effects can transformed. Supplying data z-scores sample size effect estimates standard errors give nearly identical results trait scaling.","code":""},{"path":"https://jean997.github.io/GFA/articles/gfa_with_simulated_data.html","id":"percent-of-heritability-explained","dir":"Articles","previous_headings":"","what":"Percent of Heritability Explained","title":"Running GFA with Simulated Data","text":"gfa_pve element GFA results object contains two elements, vector, genet_var matrix pve. genet_var vector gives proportion trait variance explained variants GFA fit according fitted model. estimate heritability attributable variants model. cases, underestimate total trait heritability GFA fit LD-pruned subset variants. don’t recommend GFA ideal heritability estimation tool. interesting object pve dimension traits inferred factors gives trait, proportion heritability explained factor. found even though model capture total heritability, estimates proportion heritability explained factor close truth. Using results second example, plot proportion variance explained matrix:  can compare estimated proportion heritability explained true heritability explained factor.  example, estimated proportions heritability explained tend lower truth, generally fairly close.","code":"p1 <- fit1$gfa_pve$pve %>%    plot_factors(.) +   scale_fill_gradientn(colors = c(\"white\", rev(viridis(3)))) +   xlab(\"Factor\") +   ylab(\"Trait\") #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. p1 sim_calc_pve <- function(dat){   sj <- sapply(1:ncol(dat$F_mat), function(kk){      compute_h2(b_joint = with(dat, L_mat_joint[,kk,drop = F] %*% t(F_mat[,kk, drop = F])),                  geno_scale = \"allele\",                  af = AF,                  R_LD = ld_mat_list)     }) |> matrix(nrow = nrow(dat$F_mat), byrow = FALSE)   return(sj/dat$h2) } pve_true <- sim_calc_pve(dat2)  ## order true pve and estimated pve so they can be compared sol <- min_norm(f_hat = fit1$F_hat,                  f_true = dat2$F_mat)$solution order_true <- sol$true_ix order_est <- sol$est_ix pve_est <- fit1$gfa_pve$pve[, order_est] pve_true <- pve_true[, order_true] plot(pve_true, pve_est) abline(0, 1)"},{"path":"https://jean997.github.io/GFA/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jean Morrison. Author, maintainer.","code":""},{"path":"https://jean997.github.io/GFA/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Morrison J (2025). GFA: Genetic Factor Analysis (GFA). R package version 1.0.0.0445, https://jean997.github.io/GFA/.","code":"@Manual{,   title = {GFA: Genetic Factor Analysis (GFA)},   author = {Jean Morrison},   year = {2025},   note = {R package version 1.0.0.0445},   url = {https://jean997.github.io/GFA/}, }"},{"path":"https://jean997.github.io/GFA/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Genetic Factor Analysis (GFA)","text":"Genetic Factor Analysis (GFA) R package uses factor analysis identify common genetic factors shared multiple traits. factors often interpretable shared unobserved biological processes. manuscript describing GFA can foun . vignette “Running GFA Simulated Data” provides overview GFA demonstrates run . vignette also discusses nuances like choice estimation method nuisance parameters understanding scale output estimates. applications GFA GWAS data, computational effort goes merging formatting data, can onerous, especially large number traits many sources. ease process, provided Snakemake pipeline automate steps . Using pipeline require coding familiarity Snakemake. need create spreadsheet describing data files edit human readable configuration file. cases, pipeline take care necessary pre-processing need edit, process, “munge” data using . Detailed pipeline instructions can found pipeline github, linked .","code":""},{"path":"https://jean997.github.io/GFA/index.html","id":"installation-instructions","dir":"","previous_headings":"","what":"Installation Instructions","title":"Genetic Factor Analysis (GFA)","text":"Install GFA GitHub install vignette","code":"devtools::install_github(\"jean997/GFA\") devtools::install_github(\"jean997/GFA\", build_vignettes = TRUE) browseVignettes(\"GFA\")"},{"path":"https://jean997.github.io/GFA/reference/GFA.html","id":null,"dir":"Reference","previous_headings":"","what":"GFA — GFA","title":"GFA — GFA","text":"Genetic Factor Analysis","code":""},{"path":"https://jean997.github.io/GFA/reference/GFA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"GFA — GFA","text":"Jean Morrison <jvmorr@umich.edu>","code":""},{"path":"https://jean997.github.io/GFA/reference/R_ldsc.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate matrix of error correlations using LD-score regression. — R_ldsc","title":"Calculate matrix of error correlations using LD-score regression. — R_ldsc","text":"Calculate matrix error correlations using LD-score regression.","code":""},{"path":"https://jean997.github.io/GFA/reference/R_ldsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate matrix of error correlations using LD-score regression. — R_ldsc","text":"","code":"R_ldsc(   Z_hat,   ldscores,   ld_size,   N,   return_gencov = FALSE,   make_well_conditioned = TRUE,   cond_num = 1e+05 - 1,   blocks = NULL,   ncores = 1 )"},{"path":"https://jean997.github.io/GFA/reference/R_ldsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate matrix of error correlations using LD-score regression. — R_ldsc","text":"Z_hat matrix z-scores ldscores vector ldscores ld_size Number variants used compute ldscores N vector sample sizes, length equal number columns Z_hat return_gencov TRUE, function return genetic covariance addition residual covariance/correlation. make_well_conditioned TRUE, residual covariance projected nearest positive definite matrix condition number least cond_num cond_num Condition number used make_well_conditioned = TRUE blocks NULL, use jackknife estimate standard error estimates. ncores Number cores use jackknifing","code":""},{"path":"https://jean997.github.io/GFA/reference/R_ldsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate matrix of error correlations using LD-score regression. — R_ldsc","text":"list following elements. Se: Estimate residual covariance Ve: Variance Se. Sg: genetic covariance Vg: Variance fo Sg. Rg: Genetic correlation, VRg: Variance Rg.","code":""},{"path":"https://jean997.github.io/GFA/reference/R_ldsc_quick.html","id":null,"dir":"Reference","previous_headings":"","what":"Cheater ld-score matrix. Fast but higher variance. — R_ldsc_quick","title":"Cheater ld-score matrix. Fast but higher variance. — R_ldsc_quick","text":"Cheater ld-score matrix. Fast higher variance.","code":""},{"path":"https://jean997.github.io/GFA/reference/R_ldsc_quick.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cheater ld-score matrix. Fast but higher variance. — R_ldsc_quick","text":"","code":"R_ldsc_quick(   Z_hat,   ldscores,   weights = 1/ldscores,   make_well_conditioned = TRUE,   cond_num = 1e+05,   return_cor = TRUE )"},{"path":"https://jean997.github.io/GFA/reference/R_pt.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate matrix of error correlations using p-value threshold method. — R_pt","title":"Calculate matrix of error correlations using p-value threshold method. — R_pt","text":"Calculate matrix error correlations using p-value threshold method.","code":""},{"path":"https://jean997.github.io/GFA/reference/R_pt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate matrix of error correlations using p-value threshold method. — R_pt","text":"","code":"R_pt(   B_hat,   S_hat,   p_val_thresh = 0.05,   return_cor = TRUE,   make_well_conditioned = TRUE,   cond_num = 1e+05 )"},{"path":"https://jean997.github.io/GFA/reference/R_pt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate matrix of error correlations using p-value threshold method. — R_pt","text":"B_hat Matrix effect size estimates S_hat Matrix standard errors p_val_thresh P-value threshold return_cor Return matrix correlation matrix (apply cov2cor), recommended cond_num Condition number using make_well_conditioned max_well_conditioned Project matrix nearest well conditioned positive definite matrix using Matrix::nearPD","code":""},{"path":"https://jean997.github.io/GFA/reference/R_pt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate matrix of error correlations using p-value threshold method. — R_pt","text":"traits traits matrix nuisance correlations.","code":""},{"path":"https://jean997.github.io/GFA/reference/condition.html","id":null,"dir":"Reference","previous_headings":"","what":"Project matrix to nearest well conditioned positive definite matrix. — condition","title":"Project matrix to nearest well conditioned positive definite matrix. — condition","text":"Project matrix nearest well conditioned positive definite matrix.","code":""},{"path":"https://jean997.github.io/GFA/reference/condition.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Project matrix to nearest well conditioned positive definite matrix. — condition","text":"","code":"condition(R, cond_num = 1e+05, corr = FALSE)"},{"path":"https://jean997.github.io/GFA/reference/condition.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Project matrix to nearest well conditioned positive definite matrix. — condition","text":"R Matrix cond_num Maximum allowable condition number (max(eigenvalue)/min(eigenvalue))","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_credints.html","id":null,"dir":"Reference","previous_headings":"","what":"GFA Credible Intervals — gfa_credints","title":"GFA Credible Intervals — gfa_credints","text":"Compute credible intervals various estimated parameters.","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_credints.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GFA Credible Intervals — gfa_credints","text":"","code":"gfa_credints(   gfa_fit,   nsamp = 500,   level = 0.05,   type = c(\"pve\", \"F\", \"L\"),   variant_ix = NULL )"},{"path":"https://jean997.github.io/GFA/reference/gfa_credints.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GFA Credible Intervals — gfa_credints","text":"gfa_fit object output gfa_fit. nsamp Number posterior samples. level Level credible intervals (e.g. 0.05 results 95% credible intervals). type vector including elements \"pve\", \"F\", \"L\", see details. variant_ix Optional list indices type includes \"L\".","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_credints.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"GFA Credible Intervals — gfa_credints","text":"function compute credible intervals PVE matrix, F, L depending choice \"type\". returned object include <type>\\_lower <type>\\_upper element type. Please note computing credible intervals elements L can time consuming, since L typically large. needs may better served computing frequentist estimates p-values L using gfa_loadings_gls().","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Genetic Factor Analysis — gfa_fit","title":"Genetic Factor Analysis — gfa_fit","text":"Genetic Factor Analysis","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Genetic Factor Analysis — gfa_fit","text":"","code":"gfa_fit(   Z_hat = NULL,   N = NULL,   N_case = NULL,   pop_prev = NULL,   B_hat = NULL,   S = NULL,   R = NULL,   params = gfa_default_parameters(),   no_wrapup = FALSE,   F_init = NULL,   fix_F = FALSE,   freeze_F = FALSE )"},{"path":"https://jean997.github.io/GFA/reference/gfa_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Genetic Factor Analysis — gfa_fit","text":"Z_hat matrix z-scores rows variants columns traits. N Vector sample sizes length equal number traits. provided, N default vector 1's factor matrix returned \"z-score scale\". N_case traits continuous, omit option. traits binary, N_case vector length equal number traits. Values NA continuous traits number cases binary traits. pop_prev traits continuous, omit option. traits binary, pop_prev vector length equal number traits. Values NA continuous traits population prevalence binary traits. B_hat matrix GWAS effect estimates. B_hat alternative Z_hat (provide one ). using B_hat, must also provide S. S using B_hat, provide corresponding matrix standard errors. R Estimated residual correlation matrix. can produced example using R_ldsc R_pt. params List parameters. users can left default values. See Details. no_wrapup TRUE, GFA perform wrap-steps. Advanced option used debugging. F_init Initial estimate F (optional). fix_F, freeze_F Options fixing F initialization. See Details.","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Genetic Factor Analysis — gfa_fit","text":"list elements L_hat F_hat estimated variant-factor factor-trait effects, gfa_pve contains proportion heritability explained factor, objects useful internally.","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Genetic Factor Analysis — gfa_fit","text":"can fit GFA using two types data. Either supply Z_hat N supply B_hat S. either case, GFA fit z-scores inputs factors scaled standardized trait scale liability scale binary traits. supply B_hat S, GFA guess scaling factors computing median ratio trait's standard errors compared first trait's standard errors. used B_hat/S binary traits, need supply pop_prev. use Z_hat/N binary traits, must supply N_case pop_prev. recommend using Z_hat/N option sample sizes available. params list includes following elements can modified. users need modify , except possibly `max_iter`. kmax: Maximum number factors. Defaults twice number traits cond_num: Maximum allowable condition number R. Defaults 1000. max_iter: Maximum number iterations. Defaults 1000. extrapolate: Passed flashier, defaults TRUE ebnm_fn_F ebnm_fn_L: Prior families factors loadings. Defaults point-normal. init_fn: Flashier initialization function. fix_F freeze_F provide different ways fix initial estimates. fix_F TRUE, factors supplied F_init updated. However, GFA allowed add additional factors final fit. freeze_F TRUE, GFA add additional factors final value F_hat equal F_init column scaling constants. returned object list following elements: F_hat (factor estimate), L_hat (loadings estimate), F_hat_single (columns F_hat corresponding single trait factors), F_hat_multi (columns F corresponding multi-trait factors), fit (flashier object), scale (scaling factor used), method (internal method type). zero factors, object also include gfa_pve includes genet_var (total variance explained set variants used estimation) pve traits factors matrix. (,j) element pve gives proportion trait hertiability explained factor j. compute credible intervals pve, see gfa_intervals(). compute GLS estimates factor loadings see gfa_loadings_gls().","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_loadings_gls.html","id":null,"dir":"Reference","previous_headings":"","what":"GFA generalized least squares loadings — gfa_loadings_gls","title":"GFA generalized least squares loadings — gfa_loadings_gls","text":"Compute GLS estimates p-values loadings","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_loadings_gls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"GFA generalized least squares loadings — gfa_loadings_gls","text":"","code":"gfa_loadings_gls(beta_hat, S, fit)"},{"path":"https://jean997.github.io/GFA/reference/gfa_loadings_gls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"GFA generalized least squares loadings — gfa_loadings_gls","text":"beta_hat Variants traits matrix association estimates. Traits order used produce fitted gfa object. variant set may different variant set used produce fitted gfa object. S Variants traits matrix standard errors. Variants traits match variants traits beta_hat. fit Object produced gfa_ft().","code":""},{"path":"https://jean997.github.io/GFA/reference/gfa_loadings_gls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"GFA generalized least squares loadings — gfa_loadings_gls","text":"list elements L (estimated loadings), S (standard errors loadings), P (p-values). variant factor matrices.","code":""},{"path":"https://jean997.github.io/GFA/reference/gwas_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert GWAS summary statistics to a standard format — gwas_format","title":"Convert GWAS summary statistics to a standard format — gwas_format","text":"Format GWAS summary statistics CAUSE","code":""},{"path":"https://jean997.github.io/GFA/reference/gwas_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert GWAS summary statistics to a standard format — gwas_format","text":"","code":"gwas_format(   X,   snp,   beta_hat,   se,   A1,   A2,   chrom,   pos,   p_value,   sample_size,   allele_freq,   output_file,   compute_pval = TRUE )"},{"path":"https://jean997.github.io/GFA/reference/gwas_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert GWAS summary statistics to a standard format — gwas_format","text":"X data.frame snp Column name containing SNP ID beta_hat Column name containing effect estimate se Column name containing standard error beta_hat A1 Column name containing effect allele A2 Column name containing allele chrom Chromosome column (optional) pos Position column (optional) p_value p-value column (optional) sample_size Sample size column (optional) integer output_file File write formatted data. missing formatted data returned. compute_pval Logical, compute p-value using normal approximation missing? Defaults TRUE.","code":""},{"path":"https://jean997.github.io/GFA/reference/gwas_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert GWAS summary statistics to a standard format — gwas_format","text":"data frame columns chrom, pos, snp, A1, A2, beta_hat, se, p_value, sample_size SNPs aligned effect allele. ready used gwas_merge formatted = TRUE.","code":""},{"path":"https://jean997.github.io/GFA/reference/gwas_format.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert GWAS summary statistics to a standard format — gwas_format","text":"function try merge data sets X1 X2 specified columns. necessary, flip sign effects effect allele data sets. remove variants ambiguous alleles alleles (G/C /T) alleles match data sets (e.g /G one data set /C ). remove variants simply strand flipped two data sets (e. g. /C one data set, T/G ).","code":""},{"path":"https://jean997.github.io/GFA/reference/ldsc_rg.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-Trait LD score regression — ldsc_rg","title":"Cross-Trait LD score regression — ldsc_rg","text":"Cross-Trait LD score regression","code":""},{"path":"https://jean997.github.io/GFA/reference/ldsc_rg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-Trait LD score regression — ldsc_rg","text":"","code":"ldsc_rg(   ld_score,   ld_size,   z1,   z2,   sample_size_1,   sample_size_2,   blocks = NULL,   h2_1 = NULL,   h2_2 = NULL,   intercept = NULL,   intercept_h2_1 = NULL,   intercept_h2_2 = NULL,   step1_chisq_max = 30,   chi2_thr2 = Inf,   ncores = 1 )"},{"path":"https://jean997.github.io/GFA/reference/ldsc_rg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-Trait LD score regression — ldsc_rg","text":"ld_score Vector LD scores. ld_size Number variants used compute `ld_score`. z1 Vector z-scores trait 1. z2 Vector z-scores trait 2. sample_size_1 Sample size GWAS trait 1. Possibly vector, just single value. sample_size_2 Sample size GWAS trait 2. Possibly vector, just single value. blocks Either single number specifying number blocks, vector integers specifying block number `chi2` value. Default `200` `snp_ldsc()`, dividing 200 blocks approximately equal size. `NULL` can also used skip estimating standard errors, default `snp_ldsc2()`. intercept can constrain intercept value (e.g. 0). Default `NULL` (intercept estimated). Use value 0 sure overlap GWAS samples. intercept_h2_1 Intercept heritability trait 1 (default NULL intercept estimated). intercept_h2_2 Intercept heritability trait 2 (default NULL intercept estimated). step1_chisq_max Threshold `chi2` step 1. Default `30`. chi2_thr2 Threshold `chi2` step 2. Default `Inf` (none).","code":""},{"path":"https://jean997.github.io/GFA/reference/ldsc_rg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-Trait LD score regression — ldsc_rg","text":"Vector 4 values (first 2 `blocks = NULL`):  - `[[\"int\"]]`: LDSC regression intercept,  - `[[\"int_se\"]]`: SE intercept,  - `[[\"h2\"]]`: LDSC regression estimate (SNP) heritability  - `[[\"h2_se\"]]`: SE heritability estimate.","code":""},{"path":"https://jean997.github.io/GFA/reference/min_norm.html","id":null,"dir":"Reference","previous_headings":"","what":"Minimum norm distance between true and estimated factors — min_norm","title":"Minimum norm distance between true and estimated factors — min_norm","text":"Given two matrices factors (true estimated), find rotation  minimizes Frobenius norm difference true factors  rotated estimate.","code":""},{"path":"https://jean997.github.io/GFA/reference/min_norm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Minimum norm distance between true and estimated factors — min_norm","text":"","code":"min_norm(f_true, f_hat, single_trait_thresh = 0.98, return_Q = FALSE)"},{"path":"https://jean997.github.io/GFA/reference/min_norm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Minimum norm distance between true and estimated factors — min_norm","text":"f_true Matrix true factors (M x K1) f_hat Matrix estimated factors (M x K2) single_trait_thresh Threshold identify single trait factors. factor considered single trait factor maximum absolute value entries greater threshold normalizing factor unit norm. Single trait factors removed f_true f_hat matching. Default 0.98. return_Q Logical. TRUE, return optimal rotation matrix.","code":""},{"path":"https://jean997.github.io/GFA/reference/min_norm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Minimum norm distance between true and estimated factors — min_norm","text":"list following elements: solution data frame following columns: true_ix: Index true factor est_ix: Index matching estimated factor max_true_val: Maximum absolute value true factor max_hat_val: Maximum absolute value estimated factor penalty: squared Frobenius norm penalty matched pair match_score: matching score (absolute inner product) matched pair frob_n Frobenius norm difference best matching factors. Q (optional) optimal matching matrix. Returned return_Q = TRUE. best_est (optional) best matching estimated factors. Returned return_Q = TRUE. best_true (optional) true factors corresponding best matching. Returned return_Q = TRUE.","code":""},{"path":"https://jean997.github.io/GFA/reference/plot_factors.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Factors from a matrix — plot_factors","title":"Plot Factors from a matrix — plot_factors","text":"Plot Factors matrix","code":""},{"path":"https://jean997.github.io/GFA/reference/plot_factors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Factors from a matrix — plot_factors","text":"","code":"plot_factors(   x,   row_names,   col_names,   row_order,   col_order,   row_title = \"Trait\",   col_title = \"Factor\" )"},{"path":"https://jean997.github.io/GFA/reference/plot_factors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Factors from a matrix — plot_factors","text":"row_names Labels rows col_names Labels cols row_order Order rows col_order Order columns row_title Title horizontal axis col_title Title vertical axis","code":""},{"path":"https://jean997.github.io/GFA/reference/plot_factors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Factors from a matrix — plot_factors","text":"ggplot object","code":""},{"path":"https://jean997.github.io/GFA/reference/plot_factors_bars.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot factors as barplots from a matrix — plot_factors_bars","title":"Plot factors as barplots from a matrix — plot_factors_bars","text":"Plot factors barplots matrix","code":""},{"path":"https://jean997.github.io/GFA/reference/plot_factors_bars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot factors as barplots from a matrix — plot_factors_bars","text":"","code":"plot_factors_bars(   x,   trait_names,   factor_names,   trait_order,   which_factors = seq(ncol(x)) )"},{"path":"https://jean997.github.io/GFA/reference/snp_ldsc.html","id":null,"dir":"Reference","previous_headings":"","what":"LD score regression — snp_ldsc","title":"LD score regression — snp_ldsc","text":"LD score regression","code":""},{"path":"https://jean997.github.io/GFA/reference/snp_ldsc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"LD score regression — snp_ldsc","text":"","code":"snp_ldsc(   ld_score,   ld_size,   chi2,   sample_size,   blocks = 200,   intercept = NULL,   chi2_thr1 = 30,   chi2_thr2 = Inf,   ncores = 1,   step1_index = NULL,   type = c(\"h2\", \"rg\"),   w0 = NULL )"},{"path":"https://jean997.github.io/GFA/reference/snp_ldsc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"LD score regression — snp_ldsc","text":"ld_score Vector LD scores. ld_size Number variants used compute `ld_score`. chi2 Vector chi-squared statistics. sample_size Sample size GWAS corresponding chi-squared statistics. Possibly vector, just single value. blocks Either single number specifying number blocks, vector integers specifying block number `chi2` value. Default `200` `snp_ldsc()`, dividing 200 blocks approximately equal size. `NULL` can also used skip estimating standard errors, default `snp_ldsc2()`. intercept can constrain intercept value (e.g. 1). Default `NULL` `snp_ldsc()` (intercept estimated) `1` `snp_ldsc2()` (intercept fixed 1). equivalent parameter `--intercept-h2`. chi2_thr1 Threshold `chi2` step 1. Default `30`. equivalent parameter `--two-step`. chi2_thr2 Threshold `chi2` step 2. Default `Inf` (none). type, w0, step1_index parameters used called snp_ldsc_rg","code":""},{"path":"https://jean997.github.io/GFA/reference/snp_ldsc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"LD score regression — snp_ldsc","text":"Vector 4 values (first 2 `blocks = NULL`):  - `[[\"int\"]]`: LDSC regression intercept,  - `[[\"int_se\"]]`: SE intercept,  - `[[\"h2\"]]`: LDSC regression estimate (SNP) heritability (also see    [coef_to_liab]),  - `[[\"h2_se\"]]`: SE heritability estimate.","code":""}]
